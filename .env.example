X3_DISCORD_TOKEN=YOUR_DISCORD_TOKEN
X3_GITHUB_TOKEN=YOUR_GITHUB_MARKETPLACE_TOKEN_OPTIONAL
# these can be separated with semicolons if you have multiple tokens/providers
X3_ZJ_TOKEN=YOUR_ZUKIJOUNRNEY_TOKEN_OPTIONAL
X3_HM_TOKEN=YOUR_HELIXMIND_TOKEN_OPTIONAL
X3_FRESED_TOKEN=YOUR_FRESEDGPT_TOKEN_OPTIONAL
X3_GROQ_TOKEN=YOUR_GROQ_TOKEN_OPTIONAL
X3_GOOGLE_AISTUDIO_TOKEN=YOUR_GOOGLE_AISTUDIO_TOKEN_OPTIONAL
X3_OPENROUTER_TOKEN=YOUR_OPENROUTER_TOKEN_OPTIONAL
X3_G4F_TOKEN=secret
X3_CROF_TOKEN=YOUR_CROFAI_TOKEN_OPTIONAL
X3_ELECTRONHUB_TOKEN=YOUR_ELECTRONHUB_TOKEN_OPTIONAL
X3_CABLYAI_TOKEN=YOUR_CABLYAI_TOKEN_IF_YOU_HAVE_ONE
X3_MEOWAPI_TOKEN=YOUR_MEOWAPI_TOKEN_OPTIONAL
# if you have more than one cloudflare endpoint, provide urls and tokens for all
X3_CLOUDFLARE_API_BASE=https://subdomain.someusername.workers.dev/v1 # see https://github.com/chand1012/openai-cf-workers-ai
X3_CLOUDFLARE_API_TOKEN=YOUR_ACCESS_TOKEN_1
X3_COHERE_TOKEN=YOUR_COHERE_TOKEN_OPTIONAL
X3_MNN_TOKEN=YOUR_MNN_TOKEN_OPTIONAL
X3_VOIDAI_TOKEN=YOUR_VOIDAI_TOKEN_OPTIONAL
X3_BIGMODEL_TOKEN=YOUR_BIGMODEL_TOKEN_OPTIONAL
X3_AIHORDE_API_KEY=0000000000 # will use "0000000000" if unset
X3_SELFHOSTED_API_BASE=http://localhost:8001/v1 # if you have ollama/llama-server/koboldcpp/etc running locally
X3_SELFHOSTED_API_TOKEN=secret
X3_LOG_LEVEL=debug
